{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv').\\\n",
    "                               options(header='true', \\\n",
    "                               inferschema='true') \\\n",
    "                .load(\"/home/bigdata/unswnb15_old.csv\",header=True);\n",
    "#df.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.022316,3598.0,...|    0|\n",
      "|[1.064936,1580.0,...|    0|\n",
      "|[0.072091,2958.0,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['dur',\n",
    "                                               'sbytes',\n",
    "                                               'dbytes',\n",
    "                                               'sttl',\n",
    "                                               'dttl',\n",
    "                                               'sloss',\n",
    "                                               'dloss',\n",
    "                                               'sload',\n",
    "                                               'dload',\n",
    "                                               'spkts',\n",
    "                                               'tcprtt',\n",
    "                                               'synack',\n",
    "                                               'is_sm_ips_ports',\n",
    "                                               'dpkts',\n",
    "                                               'ct_dst_sport_ltm',\n",
    "                                               'ct_dst_src_ltm',\n",
    "                                               'label'], outputCol = 'features')\n",
    "final_data = vectorAssembler.setHandleInvalid(\"keep\").transform(df)\n",
    "final_data = v_unsw_data.select(['features', 'label'])\n",
    "final_data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "# Loads data.\n",
    "#dataset = spark.read.csv('/home/bigdata/Downloads/UNSW-NB15(1).csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics by fitting the StandardScaler\n",
    "scalerModel = scaler.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each feature to have unit standard deviation.\n",
    "final_data = scalerModel.transform(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains a k-means model.\n",
    "kmeans = KMeans(featuresCol='scaledFeatures',k=3)\n",
    "model = kmeans.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Errors = 8350035.354570394\n"
     ]
    }
   ],
   "source": [
    "# Evaluate clustering by computing Within Set Sum of Squared Errors.\n",
    "#wssse = model.computeCost(final_data)\n",
    "wssse = model.summary.trainingCost\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[0.01732726 0.08893118 0.07743694 0.7746528  0.93394914 0.29681835\n",
      " 0.14847069 0.05778186 0.70245686 0.36971625 0.02060979 0.02947867\n",
      " 0.05015516 0.22039721 0.91441407 0.94325221 0.17727475]\n",
      "[3.95213248e-02 1.07240735e-01 2.23398854e-02 5.54222336e+00\n",
      " 3.84517569e+00 1.56492762e-01 3.92853206e-02 1.59784205e+00\n",
      " 4.65078234e-03 1.30338539e-01 2.69264872e+00 2.52682143e+00\n",
      " 4.20932843e-02 5.56037103e-02 1.42796568e+00 1.24770868e+00\n",
      " 2.53813847e-01]\n",
      "[3.97524980e-01 6.41434540e-01 4.72714461e+00 7.80263198e-01\n",
      " 9.74350383e-01 1.41711845e+00 4.81788648e+00 1.19338693e-03\n",
      " 5.56911181e-01 4.40880583e+00 3.97697834e-02 5.00048460e-02\n",
      " 5.55263578e-02 4.86730904e+00 2.13438340e+00 1.80666607e+00\n",
      " 1.96335340e-01]\n"
     ]
    }
   ],
   "source": [
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         2|\n",
      "|         0|\n",
      "|         0|\n",
      "|         2|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(final_data).select('prediction').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
